# Batch Connect app configuration file
#
# @note Used to define the submitted cluster, title, description, and
#   hard-coded/user-defined attributes that make up this Batch Connect app.
---

# **MUST** set cluster id here that matches cluster configuration file located
# under /etc/ood/config/clusters.d/*.yml
# @example Use the Owens cluster at Ohio Supercomputer Center
#     cluster: "owens"
cluster: "ood_oscar"
attributes:
  modules:
    value: ""
    help: "You can leave this blank if you are **not** loading additional modules. Otherwise load mulitple modules by module names seperated by spaces. For example to load mulitple  modules use: `R/3.5.1 python/2.7` "
  anaconda_module:
    widget: select
    label: "OSCAR Anaconda module"
    help: "Select the anaconda module on OSCAR  you want to run your jupyter-notebook from "
    options:
      - [ "anaconda/2-4.3.0", "anaconda/2-4.3.0"]
      - [ "anaconda/2020.02" , "anaconda/2020.02"]
      - [ "anaconda/3-5.2.0" , "anaconda/3-5.2.0"]
      - [ "anaconda/2-5.3.0" , "anaconda/2-5.3.0"]
      - [ " anaconda/3-4.3.0", "anaconda/3-4.3.0"]
  conda_env:
    value: ""
    help: "Type in the specific conda environment you want to launch the Jupyer notebook from. If you want you can choose the environment from the Jupyter interface instead presuming you have Jupyter installed in the base environment. You **will** need to provide this if Jupyter is only installed in a particular environment. The is the argument to `conda active myenv`. You would only put in `myenv` here. "
  extra_jupyter_args:
    value: ""
    help: "Any extra command line arguments to feed to the `jupyter-notebook ...` command that launches the Jupyter notebook within the batch job"
  bc_account:
    label: "Condo account"
    help: "You can leave this blank if you are **not** using a condo else enter the condo name here for example `cbc-condo`"
  bc_queue:
    value: ""
    label: "Partition"
    help: "You can leave this blank if you are using the default for your account. Else you can specify the partition you want to run the jobs on in this field. A detailed overview of the partitions on OSCAR can be found in our [docs](https://docs.ccv.brown.edu/oscar/submitting-jobs/slurm) " 
  bc_num_slots: 1
  num_cores:
    widget: "number_field"
    label: "Number of cores"
    value: 1
    help: |
      Number of cores on the Node
  memtask:
    widget: "text_field"
    value: "default"
    label: "Memory per job"
    help: |
      - **default** - Use default, 2.8 GB per task.
      - **512M** - Use 512 MB.
      - **128G** - Use 128 GB, this is the maximum on notchpeak-shared-short.
form:
  - anaconda_module
  - conda_env
  - modules
  #- jupyterlab_switch
  - extra_jupyter_args
  - num_cores
  - memtask
  - bc_account
  - bc_queue
  - bc_num_hours
  - bc_num_slots
  - bc_email_on_started
